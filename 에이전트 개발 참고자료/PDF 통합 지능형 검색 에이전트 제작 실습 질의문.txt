[Cursor 사용 PDF 통합 지능형 검색 에이전트 제작 실습 질의문]

프로젝트명 폴더명 :  AI_Agent_PDF_Search_Project

다음 요구사항을 모두 충족하는 전체 프로젝트를 생성해줘.

============================================================
📌 프로젝트 목표
============================================================
여러 PDF 문서를 자동으로 로딩하고, 텍스트를 추출한 뒤,
LangChain PDF 로더를 사용해 문서 → 임베딩 → 벡터스토어 생성까지 처리하고

- 첫 실행 시: 모든 PDF를 불러와 벡터스토어 생성 후 디스크에 저장
- 다음 실행 시: 기존에 생성된 벡터스토어를 재활용하여 빠르게 로딩

그리고 PDF 내용을 자동으로 주제별로 분류하여  
사용자에게 “주제 목록(Category List)”를 UI 화면에 출력하고,  
사용자가 특정 주제를 선택하면 해당 주제의 PDF만 검색하여 답변하는  
**지능형 PDF 검색·질의응답 Agent 시스템**을 생성하라.

LangChain v1.0의 create_agent() 최신 스타일을 반드시 사용하라.
에이전트 결과는 result["messages"][-1].content 로 읽도록 구현하라.

환경 변수는 반드시 다음과 같이 로드한다:
from dotenv import load_dotenv  
load_dotenv("C:/env/.env")

============================================================
📁 프로젝트 파일 구조 생성
============================================================
AI_Agent_PDF_Search_Project/
 ├── pdf_data                 # PDF 데이터 파일 폴더
 ├── app.py                    # Streamlit UI
 ├── agent.py                  # LangChain create_agent 기반 검색 Agent
 ├── pdf_loader.py             # LangChain PDF 로더 사용 지시
 ├── vector_store_manager.py   # 벡터스토어 생성/저장/불러오기
 ├── topic_classifier.py       # 임베딩 기반 주제 자동 생성/매핑
 ├── requirements.txt
 └── README.md


위 파일들을 모두 생성할 것.

============================================================
📄 PDF 처리 요구 사항
============================================================
1) 반드시 LangChain 공식 PDF 로더 사용:
   - PyPDFLoader 또는 UnstructuredPDFLoader 등 최신 권장 로더 사용

2) 현재 소스 경로아래 pdf_data/ 폴더에 있는 모든 PDF 로딩 후 chunking/LangChain TextSplitter 적용

3) 생성된 문서 전체를 벡터스토어(FAISS 또는 Chroma)로 인덱싱

4) 벡터스토어를 디스크에 저장하고,
   다음 실행에서는 이미 저장된 벡터스토어가 존재하면 다시 생성하지 말고 읽어올 것

   예:
   vector_store.save_local("vector_store/")
   vector_store = FAISS.load_local("vector_store/", embeddings)

5) PDF 문서별 대표 키워드를 자동 생성하여 주제 분류에 활용할 것

6) 주제별 문서 그룹핑(topic → 문서 목록) 기능 구현

============================================================
📊 UI / 기능 요구 사항
============================================================
Streamlit UI(app.py)에서 다음 기능을 제공하라:

1) “주제 목록” 자동 출력  
   - 예: ['에너지·기후', 'KTX·교통', '안전·재난', 'IoT기술', …]

2) 사용자가 주제를 클릭하면  
   - 해당 주제에 포함된 PDF들의 파일명 목록을 화면에 출력

3) 사용자가 질문을 입력하면:
   - 에이전트가 질문 내용을 기반으로 “가장 관련 있는 주제”를 자동 선택하거나,
   - 사용자가 직접 선택한 주제에 대해서만 벡터 검색을 수행

4) Agent는 LangChain v1.0 create_agent() 사용

예시 create_agent() 구조:
------------------------------------------------------------
from langchain.agents import create_agent

agent = create_agent(
    model="gpt-4o-mini",
    tools=[search_vectorstore, list_topics, select_topic],
    system_prompt="너는 PDF 통합 지능형 검색 Agent이다."
)

result = agent.invoke({
    "messages": [
        {"role": "user", "content": "기후 변화가 에너지 정책에 미치는 영향은?"}
    ]
})
------------------------------------------------------------

5) Agent는 검색 결과 요약 + 근거 제공 형식으로 답변할 것

============================================================
🤖 Agent Tool 요구 사항
============================================================
아래 도구(Tool)를 반드시 구현하여 agent에서 사용하라:

1) list_topics  
   - 현재 자동 생성된 주제 목록 반환

2) get_topic_docs  
   - 특정 topic_id에 속한 문서 파일명 리스트 반환

3) search_vectorstore  
   - 특정 topic_id 또는
   - agent가 자동 판단한 topic_id  
   에 해당하는 vectorstore에서 similarity_search 수행

4) summarize_docs  
   - 검색된 문서 chunk들을 통합 요약

에이전트는 create_agent()로 구성하며  
system_prompt에 “PDF 통합 지능형 검색 Agent” 역할을 명확히 정의한다.

============================================================
📘 README 요구 사항
============================================================
README.md에는 다음을 포함:

- 프로젝트 설명
- PDF 처리 파이프라인
- 주제 분류 방식
- LangChain create_agent() 설명
- Streamlit 실행 방법
- 벡터스토어 저장/재사용 방법
- Windows 폴더 경로 주의사항(C:/env/.env)


이 프롬프트 전체를 반영하여 전체 프로젝트를 자동 생성하라.

============================================================
[실행 방법]
C:\Users\storm\anaconda3\python.exe -m streamlit run app.py

[추가 질의-1]
주제 목록에서 주제 하나를 선택 클릭하면 핵심 키워드 목록과 질의문 예시 5개, 문서 출처등을 출력하게 해줘

[추가 질의-2]
질의에 대한 답변 결과 외에 “근거가 된 원문 문장”, “참조한 PDF 파일명”, “해당 문서의 어느 페이지인지” 까지 자동으로 출력해줘

[추가 질의-3]
PDF 문서 수가 많아도 안정적으로 시각화할 수 있는 
“AI Knowledge Graph(문서 관계 그래프)” 기능을 프로젝트에 추가해줘.

요구사항:
1) 문서 전체가 아닌 “주제(클러스터) 레벨” 관계 그래프를 먼저 생성한다.
   - 예: Cluster 0, Cluster 1, Cluster 2 …
   - 주제 간 유사도 기반으로 노드·링크 그래프 생성

2) Streamlit UI에는 먼저 주제 관계 그래프를 이미지 형태로 출력한다.
   - NetworkX 등으로 생성 → 이미지로 저장 → st.image()로 표시

3) 사용자가 특정 주제를 클릭하면,
   그 클러스터에 포함된 문서들만 대상으로 “문서 레벨 관계 그래프”를 생성한다.
   - 문서 수가 많아도 괜찮도록 해당 클러스터 내부 문서만 시각화

4) 문서 간 edges는 유사도 상위 K개(예: 3개)만 남겨서 
   그래프가 복잡해지지 않도록 Top-K 필터링 적용.

5) 관계 그래프는 모두 이미지 형태(PNG 등)로 렌더링하여 Streamlit에 출력한다.

[추가 질의-4]
PDF 주제 관계 그래프를 더 지능적으로 표현할 수 있도록 
아래 3가지 기능을 그래프 생성 로직에 통합해줘.

1) Edge 굵기 = 유사도 강도
   - 주제 간 cosine similarity 값이 높을수록 선을 굵게
   - 유사도가 낮으면 얇게
   - 유사도 threshold 또는 top-K 옵션으로 noise 제거

2) Node 크기 = 주제(cluster)에 포함된 문서 수
   - 문서 수가 많을수록 노드를 크게 표시
   - 중요도가 시각적으로 드러나게 함

3) 주제 노드 아래에 대표 키워드 2~3개 표시
   - 각 클러스터 문서로부터 공통 키워드 자동 추출
   - 예시:
       스마트시티 네트워크
       · IoT  · 센서 · 클라우드
   - 그래프만 봐도 주제 의미가 직관적으로 이해되도록 작성

위 3가지 기능을 적용하여 
주제 관계 그래프를 더 정교하고 의미 있게 시각화하도록 개선해줘.
그래프는 NetworkX 또는 유사한 라이브러리로 생성하여 
최종적으로 Streamlit에서 이미지 형태로 출력할 수 있게 구성해줘.

관계가 아주 적은것도 점선으로 희미하게 나타내줘